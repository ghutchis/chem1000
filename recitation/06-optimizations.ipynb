{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHEM 1000 - Spring 2023\n",
    "Prof. Geoffrey Hutchison, University of Pittsburgh\n",
    "Ryan Wheat, University of Pittsburgh\n",
    "\n",
    "## Recitation\n",
    "\n",
    "For this recitation, we'll focus on:\n",
    "- Numerical Optimization using Sympy\n",
    "- Numerical Optimization using Scipy\n",
    "---\n",
    "\n",
    "The goal of Chapter 6 is to give a cursory overview of the vastly expanding field that is \"optimization algorithms.\" Whether we're aware of it or not, optimization is an important concept all around us.\n",
    "\n",
    "This recitation is focused not on analytical optimization (e.g., in which we can solve for gradients and second (partial) derivatives), but for numeric optimization in which the functional form is either too complicated or unknown to solve analytically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part A: Ackley Function\n",
    "\n",
    "Sometimes determining the analytical solution to a function is not practical. In this case, one might wish to better understand the function graphically to then interpolate the extrema numerically, or to evaluate complicated Sympy expressions as floating point numbers.\n",
    "\n",
    "The Ackley function is used to test optimization methods. (There's actually a whole zoo of weird [multidimensional functions to test optimization methods](https://en.wikipedia.org/wiki/Test_functions_for_optimization).)\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "& f(x, y)=-20 \\exp \\left[-0.2 \\sqrt{0.5\\left(x^2+y^2\\right)}\\right] \\\\\n",
    "& -\\exp [0.5(\\cos 2 \\pi x+\\cos 2 \\pi y)]+e+20 \\\\\n",
    "&\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import init_session\n",
    "init_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try using sympy\n",
    "\n",
    "f = -20*exp( -0.2*sqrt( 0.5 * (x**2 + y**2)) ) - exp(0.5*(cos(2*pi*x) + cos(2*pi*y))) + exp(1) + 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show me the partial derivative for x\n",
    "dfdx = diff(f, x)\n",
    "dfdx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similar for partial derivative for y\n",
    "dfdy = diff(f, y)\n",
    "dfdy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this might run forever!\n",
    "eq1 = Eq(dfdx, 0)\n",
    "eq2 = Eq(dfdy, 0)\n",
    "solve([eq1,eq2],(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# okay, let's plot the function\n",
    "# sympy offers a contour plot function\n",
    "\n",
    "from sympy.plotting.plot import plot_contour\n",
    "%matplotlib inline\n",
    "\n",
    "plot_contour(f, (x, -5, 5), (y, -5, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the minimum is at the origin. (Spoiler: It is.)\n",
    "\n",
    "We can test this in a few ways.\n",
    "\n",
    "In Sympy, we can use `.subs` to substitute values for variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# substitute x with 0.0\n",
    "# .. feel free to try other values (e.g., 1.0, pi, etc.)\n",
    "dfdx.subs(x, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# substitute y with 0.0\n",
    "dfdy.subs(y, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we know that at (0,0) the gradient is zero. Is it a minima or a maxima?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.subs([ (x,0), (y, 0)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm pretty sure that's zero, but let's force Sympy to evaluate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N( f.subs([ (x,0), (y, 0)]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.subs([ (x,0), (y, 0)]).evalf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Close enough. We can try a few other points to convince ourselves that it's an actual minima.\n",
    "\n",
    "So as a reminder:\n",
    "- We can use `.subs( variable, value)` to substitute one variable for a number\n",
    "- We can use `.subs( [ list of (variable, value), (variable2, value2) ] )` to substitute a bunch of variables\n",
    "- We can use `N()` or `.evalf()` to force Sympy to give a number like a calculator\n",
    "\n",
    "**What if there are multiple solutions?**\n",
    "\n",
    "Sympy will give multiple solutions as a list. We know how to handle lists in Python, e.g.\n",
    "\n",
    "`list[0]` gives the first item in the list\n",
    "`len(list)` gives the length of a list\n",
    "\n",
    "That also works with Sympy, e.g.:\n",
    "\n",
    "`N(solution[0])` or `solution[0].evalf()` give the numeric result from a list of solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B: Numeric Optimization\n",
    "\n",
    "So what if you're out of luck, either because Sympy is just failing .. or you need to do numeric optimization?\n",
    "\n",
    "Fortunately, `scipy.optimize` has a `minimize` function that handles common optimization cases. We just need to code a Python function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notice that I'm using np.exp to use the numeric versions, not the Sympy versions\n",
    "def ackley(values):\n",
    "    # the parameters will be given as a list, so assign them to variables\n",
    "    x = values[0]\n",
    "    y = values[1]\n",
    "    return -20.0*np.exp(-0.2*np.sqrt(0.5*(x**2 + y**2))) - np.exp(0.5*(np.cos(2*np.pi*x) + np.cos(2*np.pi*y))) + np.exp(1) + 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ackley([0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now that we have our function to optimize, we need to pick an initial value and call `minimize()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial = np.array([0.1, 0.1])\n",
    "optima = minimize(ackley, initial)\n",
    "print(optima)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, that's a bunch to understand:\n",
    "\n",
    "- `message`: a warning or error message\n",
    "- `success`: True / False (i.e., did we reach a minimum)\n",
    "- `fun`: The value of the function at the current point\n",
    "- `x`: The current point (as a list / array)\n",
    "- `nit`: The number of iterations (steps) taken\n",
    "- `nfev`: The number of function evaluations\n",
    "\n",
    "The default optimizer is `BFGS` which takes multiple steps while estimating the gradient and the Hessian along the way. It's usually a good optimizer for most problems.\n",
    "\n",
    "Notice that while we started at (0.1, 0.1), the optimizer found its way to (0.0, 0.0) or close enough. It gave up because the gradient and Hessian became really small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's try a different point\n",
    "optima = minimize(ackley, [3.0, 3.0])\n",
    "print(optima)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait. This is weird. If we start out at (3,3) we don't find our way to the overall minima at (0, 0). This happens because we're stuck in a local minima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optima = minimize(ackley, [3.5, 3.5])\n",
    "print(optima)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optima = minimize(ackley, [2.8, 2.8])\n",
    "print(optima)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that at 2.8 or 3.5 .. anything near (3,3) will converge to the same spot.\n",
    "\n",
    "This is useful if you want to find multiple minima and you know roughly where they are.\n",
    "\n",
    "But what about maxima? How do you find maxima?\n",
    "\n",
    "The easy trick is to define a new function for minimizing that's -1.0 * maxima() and minimize *that* (e.g., you just flip your function and a maxima becomes a minima, etc.)\n",
    "\n",
    "So the main trick to numeric optimization in Python is to use `scipy.optimize.minimize()` and set up the function you want to minimize using an array of values. Supply an initial value and call `minimize()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part C: Constrained Optimization (Practice)\n",
    "\n",
    "Let's say that you are starting a company and need to hire staff and order materials. The materials (m) you need can be ordered in bulk at 50 dollars for each crate. You need to hire staff (s) to convert the materials into some product (think assembly line) at 20 dollars per hour. After consulting an entrepeneur and an engineer, you find that similar companies have used this model:\n",
    "\n",
    "$$\n",
    "f(m,s) = 5m^{2}s+2s^{2}m\n",
    "$$\n",
    "\n",
    "#### Run the code in each cell and answer the three questions below to get credit for this recitation.\n",
    "\n",
    "1. Your company has a startup fund of 600 dollars. Optimize your initial spending given the model above.\n",
    "2. Your friend is also starting a company and has been instructed to use the same model. However, you decided to give your friend two crates of material and to transfer one of your workers to their company to start production. Modify the model with these initial conditions.\n",
    "3. Your friend has applied for a startup fund and was awarded 480 dollars. Optimize spending to maximize their efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate your optimal spending.\n",
    "\n",
    "m, s = symbols(\"m s\", real=True)\n",
    "\n",
    "f = 5*s*m**2 + 2*m*s**2\n",
    "g = \n",
    "l = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your new model here...\n",
    "\n",
    "f_new = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the optimal spending for your friend.\n",
    "\n",
    "f_new = \n",
    "g = \n",
    "l = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
