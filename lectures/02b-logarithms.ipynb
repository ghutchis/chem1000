{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHEM 1000 - Spring 2024\n",
    "Prof. Geoffrey Hutchison, University of Pittsburgh\n",
    "\n",
    "## 2.b Logarithms\n",
    "\n",
    "Chapter 2 in [*Mathematical Methods for Chemists*](http://sites.bu.edu/straub/mathematical-methods-for-molecular-science/)\n",
    "\n",
    "By the end of this session, you should be able to:\n",
    "- Understand logarithms, including different bases (e.g., $\\log_{10}$, $\\log_2$, $\\log$ / $\\ln$)\n",
    "- Use Sterling's approximation to approximate $N!$ for Boltzmann entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponentials and Log\n",
    "\n",
    "We know the exponential function and $e^x$ - it goes up very fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# insert any graphs into our notebooks directly\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.style.use('./chem1000.mplstyle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(-3.0, 3.0, 0.1)\n",
    "\n",
    "plt.plot(x, np.exp(x))\n",
    "plt.plot(x, np.exp(-x))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can, of course also plot the natural log - the inverse of $e^x$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0.1, 10.0, 0.1)\n",
    "plt.plot(x, np.log(x), color='red')\n",
    "\n",
    "plt.plot(x, x*0.0, color='black') # draw a horizontal line at y = 0.0\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course we can come up with different exponential functions with different base numbers, like $e^x$ and $10^x$ and $2^x$ (which computers use). Similarly, there are multiple log functions. The most common is the natural log, te inverse of $e^x$ which is sometimes indicated with $\\ln x$. In Python we just use $\\log x = \\log_e x$.\n",
    "\n",
    "But there's also `np.log10(x)` = $\\log_{10} x$ and `np.log2(x)` = $\\log_2 x$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, np.log2(x), color='green')\n",
    "plt.plot(x, np.log(x), color='red')\n",
    "plt.plot(x, np.log10(x), color='blue')\n",
    "plt.plot(x, x*0.0, color='black') # draw a horizontal line at y = 0.0\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the smallest base (2) goes up faster than `np.log(x)` or `np.log10(x)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Arithmetic\n",
    "\n",
    "Logarithms have some extremely useful properties for simplifying complicated math, which made them critical before the invention of calculators and computers:\n",
    "\n",
    "**Multiplication** - Taking the log of a product is the same as adding two logarithms:\n",
    "$$\\log (x y)=\\log (x)+\\log (y)$$\n",
    "\n",
    "**Division** - Similarly, taking the log of a quotient is the same as subtracting two logarithms:\n",
    "\n",
    "$$\\log (\\frac{x}{y})=\\log (x) - \\log (y)$$\n",
    "\n",
    "**Powers** - Taking the log of a number to a power is similarly easy:\n",
    "\n",
    "$$\\log x^k = k \\log x$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Natural Log as Finite Difference\n",
    "\n",
    "Why is the natural log and $e^x$ so special? After all, $e$ is not an integer, it's an irrational number. We can consider the $\\log x$ function by its slope at different points:\n",
    "\n",
    "$$\\text { slope }=\\frac{\\text { rise }}{\\text { run }}=\\frac{\\Delta \\ln (x)}{\\Delta x}=\\frac{1}{x}$$\n",
    "\n",
    "Rewriting this a bit, we get:\n",
    "\n",
    "$$\\Delta \\ln (x) = \\ln(x + \\Delta x) - \\ln(x) = \\frac{\\Delta x}{x}$$\n",
    "\n",
    "So we just need to pick some $\\Delta x$ values and go from there:\n",
    "\n",
    "**Estimating Values of $\\ln x$ Using Finite Differences:**\n",
    "(from Straub, J.E. [Mathematical Methods for Chemists](http://sites.bu.edu/straub/mathematical-methods-for-molecular-science/)\n",
    "$$\n",
    "\\begin{array}{ccccc} \\hline  & & {\\ln (x)} \\\\ x & \\Delta x=3 & \\Delta x=1 & \\Delta x=0.5 & \\text { exact } \\\\ \\hline 0.0 & & -1.000 & -1.500 & -\\infty \\\\ 0.5 & & & -0.500 & -0.693 \\\\ 1.0 & 0.000 & 0.000 & 0.000 & 0.000 \\\\ 1.5 & & & 0.500 & 0.405 \\\\ 2.0 & & 1.000 & 0.833 & 0.693 \\\\ 2.5 & & & 1.083 & 0.916 \\\\ 3.0 & & 1.500 & 1.283 & 1.099 \\\\ 3.5 & & & 1.450 & 1.253 \\\\ 4.0 & 3.000 & 1.833 & 1.593 & 1.386 \\\\ 4.5 & & & 1.718 & 1.504 \\\\ 5.0 & & 2.083 & 1.829 & 1.609 \\\\ 5.5 & & & 1.929 & 1.705 \\\\ 6.0 & & 2.283 & 2.020 & 1.792 \\\\ 6.5 & & & 2.103 & 1.872 \\\\ 7.0 & 3.750 & 2.450 & 2.180 & 1.946 \\\\ 7.5 & & & 2.252 & 2.015 \\\\ 8.0 & & 2.593 & 2.318 & 2.079 \\\\ 8.5 & & & 2.381 & 2.140 \\\\ 9.0 & & 2.718 & 2.440 & 2.197 \\\\ 9.5 & & & 2.495 & 2.251 \\\\ 10.0 & 4.179 & 2.829 & 2.548 & 2.303 \\\\ \\hline\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finite difference for log(x): Δlog(x) = log(x + Δx) - log(x) = Δx/x\n",
    "delta_x = 0.5\n",
    "log = 0.0 # at x = 1 by definition\n",
    "x = 1.0\n",
    "total_steps = int(10.0 / delta_x) - 1 # the number of steps from 1 to 10 given delta_x\n",
    "\n",
    "for step in range(total_steps):\n",
    "    print(round(x, 2), round(log, 4))\n",
    "    # get the values for the next step\n",
    "    log = log + delta_x / x\n",
    "    x = x + delta_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applications\n",
    "\n",
    "Why all the bother with logarithms? We use them frequently in science.\n",
    "\n",
    "$$\\mathrm{pH}=-\\log _{10}\\left(a_{H^{+}}\\right)$$\n",
    "\n",
    "In other words, an acidic solution $[H^+] = 10^{-1}$ for pH = 1, while a basic solution might have $[H^+] = 10^{-12}$ for pH = 12. We don't talk about it frequently, but that's 12 - 1 = 11 orders of magnitude difference in concentration, only 100,000,000,000. Not many things differ by over 100 billion.\n",
    "\n",
    "**Length Scales**\n",
    "\n",
    "An atom is ~1Å in radius, or $10^{-10} m$ and the radius of Earth is $\\sim 10^{7} m$, only 17 orders of magnitude. From an atomic nucleus to the size of the known universe is 41 orders of magnitude - literally astronomically large numbers!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logarithm and Entropy\n",
    "\n",
    "Logarithms also have key aspect in entropy. Boltzmann's entropy formula is:\n",
    "\n",
    "$$ S = k_b \\ln W $$\n",
    "\n",
    "where $k_b$ is the Boltzmann constant and $W$ is the number of possible states. (Incidentally, this formula is [engraved on his grave](https://en.wikipedia.org/wiki/Ludwig_Boltzmann#Second_thermodynamics_law_as_a_law_of_disorder).)\n",
    "\n",
    "Let's think about this in the context of the entropy of a few books -- let's say three. I can arrange them in $3! = 6$ ways (ABC, CAB, BCA, … etc.). The entropy isn't very large because I don't have so many arrangement states.\n",
    "\n",
    "Instead, let's consider the number of possible states for a deck of 52 cards: $52!$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 52\n",
    "total = 1\n",
    "for i in range(1, 52+1): # range will go from start to end-1 and we want 1..52\n",
    "    total = total * i\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, that's a big number... 68 digits.. Let's plot a few parts of `n!` maybe to 10! and see how it goes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "y = [] # start with an empty list\n",
    "for n in x:\n",
    "    y.append(math.factorial(n)) # add n! for each item in x\n",
    "\n",
    "plt.plot(x, y, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It goes up fast, but a bit hard to understand - just that it goes from under 500k for 9! to over 3.5 million for 10! Let's try using a logarithmic y-axis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, y, color='red')\n",
    "plt.plot(x, np.exp(x), color='black')\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Woah. Factorial starts slow.\n",
    "- 1! = 1\n",
    "- 2! = 2\n",
    "- 3! = 6\n",
    "- 4! = 24\n",
    "\n",
    "But then it goes up *faster* than the exponential line in black.\n",
    "- 5! = 120\n",
    "- 6! = 720\n",
    "\n",
    "Clearly having an approximation to $\\log N!$ would be useful for entropy. We can use the rules for log arithmetic above:\n",
    "\n",
    "$$\\log N! = \\log [ N \\times (N-1) \\times \\cdots \\times 2 \\times 1] = \\log 1 + \\log 2 + \\cdots \\log N$$\n",
    "\n",
    "$$\\ln N !=\\sum_{n=1}^{N} \\ln (n) $$\n",
    "\n",
    "If N gets really big, we can approximate by using an integral:\n",
    "\n",
    "$$\\ln N ! \\approx \\int_{1}^{N} \\ln (n) d n=[n \\ln n-n]_{1}^{N}=N \\ln N-N+1$$\n",
    "\n",
    "This is known as [Sterling's approximation](https://en.wikipedia.org/wiki/Stirling%27s_approximation), named after James Sterling, although it was first stated by [de Moivre](https://en.wikipedia.org/wiki/Abraham_de_Moivre).\n",
    "\n",
    "Given Sterling's formula, can we evaluate the entropy for a mole of atoms?\n",
    "\n",
    "$$\n",
    "\\begin{aligned} \\ln \\left(6.02 \\times 10^{23}\\right) & \\approx\\left(6.02 \\times 10^{23}\\right) \\ln \\left(6.02 \\times 10^{23}\\right)-6.02 \\times 10^{23}+1 \\\\ &=3.30 \\times 10^{25}-6.02 \\times 10^{23}+1 \\\\ &=3.24 \\times 10^{25} \\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's how we definie a new function in Python\n",
    "def sterling(n):\n",
    "    n_log_n = n * math.log(n)\n",
    "    return n_log_n - n + 1  # here's how the function returns a value\n",
    "\n",
    "def sterling_factorial(n):\n",
    "    return math.exp(sterling(n))\n",
    "\n",
    "print('log 5!', sterling(5))\n",
    "print('5!', sterling_factorial(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that 5! is 120, so it's not particularly accurate for small numbers, but it's possible to evaluate $\\log(N_a)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('log mol!', sterling(6.02e23))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a slightly more accurate version in the textbook - instead of +1 in the last term:\n",
    "\n",
    "$$ N ! \\approx \\sqrt{2 \\pi N}(N / e)^{N} $$\n",
    "$$ \\ln N! \\approx N \\ln N-N + \\frac{1}{2} \\ln(2\\pi N)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new version of our log n! formula\n",
    "def sterling_v2(n):\n",
    "    n_log_n = n * math.log(n)\n",
    "    return n_log_n - n + 0.5 * math.log(2*math.pi * n)\n",
    "\n",
    "print('log mol!', sterling_v2(6.02e23))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's not a typo, the difference on $6.02 \\times 10^{23}$ doesn't even show up to the 16th decimal place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('log n!', sterling(5))\n",
    "print('n!', math.exp(sterling(5)))\n",
    "\n",
    "print('v2: log n!', sterling_v2(5))\n",
    "print('v2: n!', math.exp(sterling_v2(5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It ***definitely*** makes a difference on small numbers though. Remember 5! = 120, so 118 is fairly close."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ramanujan's Approximation\n",
    "\n",
    "Beyond Sterling, [Ramanujan](https://en.wikipedia.org/wiki/Srinivasa_Ramanujan), an Indian mathematician with almost no formal training in mathematics:\n",
    "> He tried to interest the leading professional mathematicians in his work, but failed for the most part. What he had to show them was too novel, too unfamiliar, and additionally presented in unusual ways; they could not be bothered.\n",
    "\n",
    "Among many, many other works, we find that Ramanujan also came up with an [approximation for factorials](https://www.johndcook.com/blog/2012/09/25/ramanujans-factorial-approximation/):\n",
    "\n",
    "$$n ! \\sim \\sqrt{\\pi}\\left(\\frac{n}{e}\\right)^{n} \\sqrt[6]{8 n^{3}+4 n^{2}+n+\\frac{1}{30}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementation of Ramanujan's factorial approximation\n",
    "# adapted from John Cook: https://www.johndcook.com/blog/2012/09/25/ramanujans-factorial-approximation/\n",
    "def ramanujan(n):\n",
    "    fact = math.sqrt(math.pi)*(n/math.e)**n\n",
    "    fact *= (((8*n + 4)*n + 1)*n + 1/30.)**(1./6.)\n",
    "    return fact\n",
    "\n",
    "ramanujan(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that even the improved form of Sterling's approximation got 118, and the real answer is 120.\n",
    "\n",
    "On the other hand, it's fairly easy to remember $\\ln N! = N \\ln N - N + 1$. It's just important to remember that there are often more accurate methods available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "This notebook is from Prof. Geoffrey Hutchison, University of Pittsburgh\n",
    "https://github.com/ghutchis/chem1000\n",
    "\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by/4.0/88x31.png\" /></a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
