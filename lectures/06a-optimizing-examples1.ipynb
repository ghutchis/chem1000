{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHEM 1000 - Spring 2024\n",
    "Prof. Geoffrey Hutchison, University of Pittsburgh\n",
    "\n",
    "## 6 Optimizing Functions (Examples)\n",
    "\n",
    "Chapter 6 in [*Mathematical Methods for Chemists*](http://sites.bu.edu/straub/mathematical-methods-for-molecular-science/)\n",
    "\n",
    "By the end of this session, you should be able to:\n",
    "- Understand general approaches to optimize functions either for minima or maxima (i.e. \"extrema\")\n",
    "- Understand how to use derivatives in multiple dimensions to categorize extrema\n",
    "- Using `scipy.optimize` to do numeric optimization of complicated functions\n",
    "  - (We'll have more examples for both algebra/calculus and numerical optimization in recitation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Summary\n",
    "\n",
    "In chemistry and physics, we often want to determine the maximum or minimum value of a function of one or many variables. Examples include characterizing the minima, maxima, and saddle points on a potential energy surface.\n",
    "\n",
    "Optimizing functions in one dimension is pretty easy, if sometimes tedious.\n",
    "1. Take derivatives and find where the first derivative is zero\n",
    "2. Look at the second derivatives, to categorize as a minima / maxima / inflection point\n",
    "3. Then compare values of the function at those points to see if it's a local minima / max or the global minima / max.\n",
    "\n",
    "### Many Variables\n",
    "\n",
    "Not surprisingly, we can use a similar technique in multiple dimensions.\n",
    "\n",
    "If we have a function $f(x,y)$ in two dimensions, then to have an extrema:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial f}{\\partial x}=0 \\quad \\frac{\\partial f}{\\partial y}=0\n",
    "$$\n",
    "\n",
    "In other words, we need to see the partial derivative with respect to **both / all** variables be zero.\n",
    "\n",
    "We can then categorize the type of minima / maxima with the [Hessian]. (Later, we will see that this is the *determinant* of the Hessian matrix, for when we have more than 2 variables.)\n",
    "\n",
    "$$\n",
    "D=\\left(\\frac{\\partial^{2} f}{\\partial x^{2}}\\right)\\left(\\frac{\\partial^{2} f}{\\partial y^{2}}\\right)-\\left(\\frac{\\partial^{2} f}{\\partial x \\partial y}\\right)\\left(\\frac{\\partial^{2} f}{\\partial y \\partial x}\\right)\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\left.\\frac{\\partial^{2} f}{\\partial x^{2}}\\right|_{\\left(x^{*}, y^{*}\\right)}=\\left\\{\\begin{array}{ll}\n",
    "<0 & D>0 & \\text { maximum } \\\\\n",
    ">0 & D>0 & \\text { minimum } \\\\\n",
    " & D < 0 & \\text { saddle-point }\n",
    "\\end{array}\\right.\n",
    "$$\n",
    "\n",
    "### Example:\n",
    "\n",
    "Let's try the so-called \"butterfly potential\"\n",
    "\n",
    "$$\n",
    "V(x, y)=\\left((x-y)^{2}-1\\right)^{2}+10 x^{2} y^{2}\n",
    "$$\n",
    "\n",
    "<img src='../images/butterfly-potential.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sympy import init_session\n",
    "init_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = ((x-y)**2-1)**2 + 10*x**2*y**2\n",
    "V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# okay, let's see where the partial derivative with x is zero...\n",
    "diff(V, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's do y\n",
    "diff(V, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, we can't do this so easily - we have two equations and two unknowns.\n",
    "\n",
    "Fortunately, sympy offers some nice features:\n",
    "- Eq(*expression*, value) sets up an equation like $x = 0$\n",
    "  - We can set our derivatives as equal to zero\n",
    "- solve() can take multiple equations and multiple unknowns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eq1 = Eq(diff(V, x), 0) # partial derivative with x == 0\n",
    "eq2 = Eq(diff(V, y), 0) # partial derivative with y == 0\n",
    "solve((eq1,eq2), (x, y)) # solve two equations for two unknowns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here's the two-variable Hessian test...\n",
    "D = diff(V, x, 2)*diff(V, y, 2) - diff(V, x, y)*diff(V, y, x)\n",
    "D # print it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, I like when the computer does math for me..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can use the .subs() method to substitute values (-1, 0)\n",
    "D.subs([ (x, -1), (y, 0) ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, that's $D > 0$ so we need to check the second derivative (at -1, 0) to see if we're at a max or min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dVdx2 = diff(V, x, x)\n",
    "# use f.subs() to substitute x for -1 and y for 0\n",
    "dVdx2.subs([ (x, -1), (y, 0) ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second derivative is positive, so this is a minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check (0,0)\n",
    "D.subs([ (x, 0), (y, 0) ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The origin is inconclusive - because it's something like a saddle point, but there are four wells around it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now check (+1, 0)\n",
    "D.subs([ (x, 1), (y, 0) ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, this point is positive, so we need to check for a maximum or minimum. (It's another minimum)\n",
    "\n",
    "Instead, let's look at the $\\frac{\\sqrt 26}{13}$ points..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D.subs([ (x, sqrt(26)/13), (y, -sqrt(26)/13) ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This point has $D < 0$ so these are saddle points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another Example\n",
    "\n",
    "Let's try $$f(x,y) = x^2y - 2xy^2 + 3xy + 4$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = x**2*y - 2*x*y**2 + 3*x*y + 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to look where the derivatives are both zero..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# take derivatives\n",
    "dfdx = diff(f, x)\n",
    "dfdy = diff(f, y)\n",
    "\n",
    "# solve for where x == y == 0\n",
    "solve((dfdx,dfdy), (x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, let's get the determinant of the Hessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = diff(f, x, 2)*diff(f, y, 2) - diff(f, x, y)*diff(f, y, x)\n",
    "D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we check each of these points to classify them..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "D.subs([(x, -3), (y, 0)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(-3, 0) is a saddle point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D.subs([(x, -1), (y, 0.5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, let's check the second derivative to see if it's a max or min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff(f, x, 2).subs([(x, -1), (y, 0.5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimum. Next point?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D.subs([(x, 0), (y, 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D.subs([(x, 0), (y, 1.5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, both of these are saddle points. So the function has 3 saddle points and a minimum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Water\n",
    "\n",
    "We looked at a one-dimensional Lennard-Jones potential.\n",
    "\n",
    "Here, I've calculated the O-H bond stretch in water, using the RI-MP2 method and the cc-pVTZ basis set. (Don't worry, you don't need to know what that means, but we're aiming for a relatively accurate quantum chemical method.)\n",
    "\n",
    "<img src=\"../images/water-bond.png\" width=\"500\"/>\n",
    "\n",
    "Most bonds fit well to a [Morse Potential](https://en.wikipedia.org/wiki/Morse_potential) like this. There are reasons to use other functional forms (e.g., speed), but this relatively simple form captures a lot of how real covalent bonds behave.\n",
    "\n",
    "I also calculated the H-O-H bond angle bend using the same method. Fortunately, this (like many angle bends) fit well to a quadratic function:\n",
    "          \n",
    "<img src=\"../images/water-angle.png\" width=\"500\" />\n",
    "\n",
    "The total potential energy will be:\n",
    "\n",
    "$$\n",
    "V = V_{bond} + V_{angle}\n",
    "$$\n",
    "\n",
    "In principle, there are \"cross-terms\" (e.g., stretch-bend) involving both $r$ and $\\theta$ but it's always good to start with a simple model and get more complex once we understand that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll declare new symbols for now\n",
    "r, theta = symbols(\"r theta\")\n",
    "bond = 265.79*(1 - exp((-2.2534)*(r - 0.96242)))**2\n",
    "angle = 167.16 - 3.217*theta + 0.01548*theta**2\n",
    "V = bond + angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's solve for the derivative w.r.t. theta equal to zero\n",
    "solve( diff(angle, theta) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff(bond, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't run this, it will go forever\n",
    "solve(diff(bond, r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oof, that's a hard one to solve. We know that the minimum value is around 0.96Å, so we can try this numerically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr = diff(bond, r)\n",
    "lengths = [0.93, 0.94, 0.95, 0.96, 0.97, 0.98]\n",
    "for l in lengths:\n",
    "    print(l, round(bond.subs(r, l), 4), round(dr.subs(r, l), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly 0.96Å is very close. Notice that the partial derivative goes from negative to positive between 0.96Å and 0.97Å.\n",
    "\n",
    "We can interpolate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for digit in range(0, 10):\n",
    "    l = 0.96 + digit/1000\n",
    "    print(l, round(bond.subs(r, l), 4), round(dr.subs(r, l), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can go further, but ~0.9625Å seems like a fairly accurate estimate of the optimal bond length.\n",
    "\n",
    "I picked this example because sometimes we want to use several methods (e.g., both calculus and numerical methods) to solve problems.\n",
    "\n",
    "We discussed using `scipy.optimize.minimize` to solve numeric problems:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# it also has a bunch of minimize methods\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# we have to define the function to evaluate\n",
    "def water(parameters):\n",
    "    r, theta = parameters\n",
    "    bond = 265.79*(1 - np.exp((-2.2534)*(r - 0.96242)))**2\n",
    "    angle = 167.16 - 3.217*theta + 0.01548*theta**2\n",
    "    return bond + angle\n",
    "\n",
    "# and here's how we call it, e.g. r = 0.98A and theta = 108°\n",
    "water([0.98, 108])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `scipy.optimize` minimize() function has a bunch of related methods. The most useful for most purposes:\n",
    "\n",
    "* `method ='CG'` for [conjugate gradients](https://en.wikipedia.org/wiki/Conjugate_gradient_method) \n",
    "   * like \"skiing downhill\"\n",
    "   * calculates gradients / derivatives using numeric approximation if needed \n",
    "   * .. steps \"downhill\"\n",
    "   * calculates new gradients .. and continues but not always exactly in the steepest direction\n",
    "   * finishes when gradients / derivatives are \"close to zero\"\n",
    "* `method = 'BFGS'` for [BFGS algorithm](https://en.wikipedia.org/wiki/Broyden–Fletcher–Goldfarb–Shanno_algorithm)\n",
    "   * calculates an approximation to the Hessian matrix\n",
    "   * also uses gradients / derivatives using numeric approximation if needed\n",
    "   * usually faster / fewer steps than CG\n",
    "   * a bit harder to code if you're writing it yourself\n",
    "   * also finishes when gradients are close to zero .. and Hessian has no negative values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# we need to start with initial parameters\n",
    "x0 = [0.96, 108]\n",
    "# CG = \"conjugate gradients\" minimize\n",
    "optima = minimize(water, x0, method='CG', options={'disp': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# here's how we get the parameters:\n",
    "print(optima.x)\n",
    "# and here's the value of the function at the minimum parameters:\n",
    "print(\"energy = \", optima.fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# use the same starting parameters\n",
    "optima = minimize(water, x0, method='BFGS', options={'disp': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(optima.x)\n",
    "print(\"energy = \", optima.fun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that BFGS used many fewer steps (4 vs. 19) and only 32 function evaluations (vs. 212 for CG).\n",
    "\n",
    "In other words, if you can, BFGS is a really, really good numeric minimization method.\n",
    "\n",
    "Why would you use conjugate gradients instead? Well, if you're writing the code, BFGS is more complicated. Writing CG is pretty easy .. just calculate the gradients and figure out how far of a step to take. Repeat.\n",
    "\n",
    "BFGS is harder and uses more memory because it builds up an approximation to the Hessian.\n",
    "\n",
    "So if I don't have `scipy.optimize` and I'm writing code myself.. I might use CG just because I'm lazy and I want the computer to do the work for me.\n",
    "\n",
    "One last caveat.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "Numeric optimization methods will only find <strong>local</strong> minima (or maxima) near your initial point. So if you want to find <emph>all</emph> minima or maxima, you need to sample multiple initial points.\n",
    "</div"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "This notebook is from Prof. Geoffrey Hutchison, University of Pittsburgh\n",
    "https://github.com/ghutchis/chem1000\n",
    "\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by/4.0/88x31.png\" /></a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
